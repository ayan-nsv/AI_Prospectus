from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
import time
import re
import threading
from urllib.parse import urlparse

# Semaphore to limit concurrent Selenium instances (max 3 at a time)
_selenium_semaphore = threading.Semaphore(3)

# Cache ChromeDriver path to avoid repeated installations
_chromedriver_path = None
_chromedriver_lock = threading.Lock()

def _get_chromedriver_path():
    """Get ChromeDriver path, caching it to avoid repeated installations"""
    global _chromedriver_path
    if _chromedriver_path:
        return _chromedriver_path
    
    with _chromedriver_lock:
        # Double-check after acquiring lock
        if _chromedriver_path:
            return _chromedriver_path
        
        try:
            _chromedriver_path = ChromeDriverManager().install()
            return _chromedriver_path
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to install ChromeDriver: {e}")
            return None

def _force_cleanup_driver(driver):
    """Force cleanup of ChromeDriver process"""
    if not driver:
        return
    
    try:
        driver.quit()
    except:
        pass
    
    try:
        if hasattr(driver, 'service') and driver.service and driver.service.process:
            try:
                driver.service.process.terminate()
                driver.service.process.wait(timeout=5)
            except:
                try:
                    driver.service.process.kill()
                except:
                    pass
    except:
        pass

def search_company_google(email: str) -> str:
    domain = email.split('@')[-1].strip()  # FIXED: removed [0]
    query = f"{domain} company"

    print(f"üîç Searching Google for: {query}")

    chrome_options = Options()
    chrome_options.binary_location = "/usr/bin/google-chrome-stable" 
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("--disable-web-security")
    chrome_options.add_argument("--disable-features=VizDisplayCompositor")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    _selenium_semaphore.acquire()
    driver = None
    
    try:
        # Get cached ChromeDriver path
        chromedriver_path = _get_chromedriver_path()
        if not chromedriver_path:
            print(f"‚ö†Ô∏è ChromeDriver not available, skipping Google search")
            return None
        
        # Retry logic for driver initialization
        max_retries = 2
        for attempt in range(max_retries):
            try:
                driver = webdriver.Chrome(service=Service(chromedriver_path), options=chrome_options)
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è ChromeDriver init attempt {attempt + 1} failed, retrying...")
                    time.sleep(1)
                    # Reset cached path to force reinstall on next call
                    global _chromedriver_path
                    _chromedriver_path = None
                    chromedriver_path = _get_chromedriver_path()
                    if not chromedriver_path:
                        return None
                else:
                    raise
        
        if not driver:
            return None
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        driver.set_page_load_timeout(20)  # Reduced timeout
        driver.implicitly_wait(5)
        
        print(f"üåê Loading Google search...")
        driver.get(f"https://www.google.com/search?q={query}")
        
        # Wait for results to load
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div.g, div.tF2Cxc, h3"))
            )
        except TimeoutException:
            print("‚è±Ô∏è Timeout waiting for Google results")
            return None
        
        time.sleep(2)  # Additional settling time

        # Try multiple selectors for Google search results
        selectors_to_try = [
            "div.tF2Cxc",  # Most reliable modern selector
            "div.g",  # Standard Google result container
            "div[data-sokoban-container]",  # Alternative container
            "div.yuRUbf",  # Another common selector
        ]
        
        results_found = []
        for selector in selectors_to_try:
            try:
                print(f"üîç Trying selector: {selector}")
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                print(f"   Found {len(elements)} elements with {selector}")
                
                if elements:
                    for i, element in enumerate(elements[:10]):  # Check more results
                        try:
                            # Get title from h3
                            title_elem = element.find_element(By.CSS_SELECTOR, "h3")
                            title = title_elem.text.strip()
                            
                            # Get link
                            link = ""
                            try:
                                link_elem = element.find_element(By.CSS_SELECTOR, "a")
                                link = link_elem.get_attribute("href")
                            except:
                                pass
                            
                            if title and len(title) > 2:
                                results_found.append({
                                    'title': title,
                                    'link': link,
                                    'selector': selector,
                                    'index': i
                                })
                                print(f"   üìÑ Result {i+1}: {title[:60]}...")
                                
                        except Exception as e:
                            continue
                    
                    if results_found:
                        break  # Found results with this selector
                        
            except Exception as e:
                print(f"   ‚ùå Selector {selector} failed: {e}")
                continue

        print(f"üìä Total results found: {len(results_found)}")
        
        # Extract domain parts for matching
        domain_base = extract_domain_base(domain)
        
        # Score and rank results
        scored_results = []
        for result in results_found:
            score = score_result(result['title'], result['link'], domain, domain_base)
            scored_results.append({**result, 'score': score})
        
        # Sort by score (highest first)
        scored_results.sort(key=lambda x: x['score'], reverse=True)
        
        # Return the best match if it meets threshold
        if scored_results and scored_results[0]['score'] > 0:
            best = scored_results[0]
            print(f"‚úÖ Best match (score: {best['score']}): {best['title']}")
            return clean_company_name(best['title'])

        print("‚ùå Google search failed to find valid company name")
        return None

    except Exception as e:
        print(f"‚ùå Google search error: {e}")
        return None
    finally:
        _force_cleanup_driver(driver)
        _selenium_semaphore.release()


def search_company_bing(email: str) -> str:
    domain = email.split('@')[-1].strip()
    query = f"{domain} company"

    print(f"üîç Searching Bing for: {query}")

    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    _selenium_semaphore.acquire()
    driver = None
    
    try:
        # Get cached ChromeDriver path
        chromedriver_path = _get_chromedriver_path()
        if not chromedriver_path:
            print(f"‚ö†Ô∏è ChromeDriver not available, skipping Bing search")
            return None
        
        # Retry logic for driver initialization
        max_retries = 2
        for attempt in range(max_retries):
            try:
                driver = webdriver.Chrome(service=Service(chromedriver_path), options=chrome_options)
                driver.set_page_load_timeout(20)  # Reduced timeout
                driver.implicitly_wait(5)
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è ChromeDriver init attempt {attempt + 1} failed, retrying...")
                    time.sleep(1)
                    # Reset cached path to force reinstall on next call
                    global _chromedriver_path
                    _chromedriver_path = None
                    chromedriver_path = _get_chromedriver_path()
                    if not chromedriver_path:
                        return None
                else:
                    raise
        
        if not driver:
            return None
        
        print(f"üåê Loading Bing search...")
        driver.get(f"https://www.bing.com/search?q={query}")
        
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "li.b_algo, h2 a"))
            )
        except TimeoutException:
            print("‚è±Ô∏è Timeout waiting for Bing results")
            return None
            
        time.sleep(2)

        # Bing selectors
        selectors_to_try = [
            "li.b_algo",  # Standard Bing result container
            "div.b_title",  # Title container
        ]
        
        results_found = []
        for selector in selectors_to_try:
            try:
                print(f"üîç Trying Bing selector: {selector}")
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                print(f"   Found {len(elements)} elements with {selector}")
                
                if elements:
                    for i, element in enumerate(elements[:10]):
                        try:
                            title_elem = element.find_element(By.CSS_SELECTOR, "h2 a, a")
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute("href")
                            
                            if title and len(title) > 2:
                                results_found.append({
                                    'title': title,
                                    'link': link,
                                    'index': i
                                })
                                print(f"   üìÑ Bing Result {i+1}: {title[:60]}...")
                                
                        except Exception as e:
                            continue
                    
                    if results_found:
                        break
                        
            except Exception as e:
                print(f"   ‚ùå Bing selector {selector} failed: {e}")
                continue

        print(f"üìä Total Bing results found: {len(results_found)}")
        
        domain_base = extract_domain_base(domain)
        
        # Score results
        scored_results = []
        for result in results_found:
            score = score_result(result['title'], result['link'], domain, domain_base)
            scored_results.append({**result, 'score': score})
        
        scored_results.sort(key=lambda x: x['score'], reverse=True)
        
        if scored_results and scored_results[0]['score'] > 0:
            best = scored_results[0]
            print(f"‚úÖ Best Bing match (score: {best['score']}): {best['title']}")
            return clean_company_name(best['title'])

        print("‚ùå Bing search failed to find valid company name")
        return None

    except Exception as e:
        print(f"‚ùå Bing search error: {e}")
        return None
    finally:
        _force_cleanup_driver(driver)
        _selenium_semaphore.release()


def search_company_duckduckgo(email: str) -> str:
    domain = email.split('@')[-1].strip()
    query = f"{domain} company"

    print(f"üîç Searching DuckDuckGo for: {query}")

    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    _selenium_semaphore.acquire()
    driver = None
    
    try:
        # Get cached ChromeDriver path
        chromedriver_path = _get_chromedriver_path()
        if not chromedriver_path:
            print(f"‚ö†Ô∏è ChromeDriver not available, skipping DuckDuckGo search")
            return None
        
        # Retry logic for driver initialization
        max_retries = 2
        for attempt in range(max_retries):
            try:
                driver = webdriver.Chrome(service=Service(chromedriver_path), options=chrome_options)
                driver.set_page_load_timeout(20)  # Reduced timeout
                driver.implicitly_wait(5)
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è ChromeDriver init attempt {attempt + 1} failed, retrying...")
                    time.sleep(1)
                    # Reset cached path to force reinstall on next call
                    global _chromedriver_path
                    _chromedriver_path = None
                    chromedriver_path = _get_chromedriver_path()
                    if not chromedriver_path:
                        return None
                else:
                    raise
        
        if not driver:
            return None
        
        print(f"üåê Loading DuckDuckGo search...")
        driver.get(f"https://duckduckgo.com/?q={query}")
        
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "article, h2"))
            )
        except TimeoutException:
            print("‚è±Ô∏è Timeout waiting for DuckDuckGo results")
            return None
            
        time.sleep(2)

        # DuckDuckGo selectors
        selectors_to_try = [
            "article[data-testid='result']",  # Modern DDG
            "article",  # Standard DuckDuckGo result container
            "div.result",  # Older selector
        ]
        
        results_found = []
        for selector in selectors_to_try:
            try:
                print(f"üîç Trying DuckDuckGo selector: {selector}")
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                print(f"   Found {len(elements)} elements with {selector}")
                
                if elements:
                    for i, element in enumerate(elements[:10]):
                        try:
                            # Try multiple ways to find title link
                            title_elem = None
                            try:
                                title_elem = element.find_element(By.CSS_SELECTOR, "h2 a")
                            except:
                                try:
                                    title_elem = element.find_element(By.CSS_SELECTOR, "a[data-testid='result-title-a']")
                                except:
                                    title_elem = element.find_element(By.CSS_SELECTOR, "a")
                            
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute("href")
                            
                            if title and len(title) > 2:
                                results_found.append({
                                    'title': title,
                                    'link': link,
                                    'index': i
                                })
                                print(f"   üìÑ DuckDuckGo Result {i+1}: {title[:60]}")
                                
                        except Exception as e:
                            continue
                    
                    if results_found:
                        break
                        
            except Exception as e:
                print(f"   ‚ùå DuckDuckGo selector {selector} failed: {e}")
                continue

        print(f"üìä Total DuckDuckGo results found: {len(results_found)}")
        
        domain_base = extract_domain_base(domain)
        
        # Score results
        scored_results = []
        for result in results_found:
            score = score_result(result['title'], result['link'], domain, domain_base)
            scored_results.append({**result, 'score': score})
        
        scored_results.sort(key=lambda x: x['score'], reverse=True)
        
        if scored_results and scored_results[0]['score'] > 0:
            best = scored_results[0]
            print(f"‚úÖ Best DDG match (score: {best['score']}): {best['title']}")
            return clean_company_name(best['title'])

        print("‚ùå DuckDuckGo search failed to find valid company name")
        return None

    except Exception as e:
        print(f"‚ùå DuckDuckGo search error: {e}")
        return None
    finally:
        _force_cleanup_driver(driver)
        _selenium_semaphore.release()


def extract_domain_base(domain: str) -> str:
    """Extract the main part of domain (e.g., 'google' from 'google.com')"""
    parts = domain.split('.')
    # Handle cases like co.uk, com.au
    if len(parts) >= 2:
        return parts[-2].lower()
    return domain.lower()


def score_result(title: str, link: str, full_domain: str, domain_base: str) -> int:
    """
    Score a search result based on relevance to the domain.
    Higher score = better match
    """
    score = 0
    title_lower = title.lower()
    link_lower = link.lower() if link else ""
    
    # Parse URL domain
    url_domain = ""
    if link:
        try:
            parsed = urlparse(link)
            url_domain = parsed.netloc.lower()
        except:
            pass
    
    # Strong positive signals
    if domain_base in url_domain:
        score += 100  # Link contains the domain
    
    if full_domain in url_domain:
        score += 50  # Exact domain match
    
    # Company name in title (without common suffixes)
    clean_title = clean_company_name(title).lower()
    if domain_base in clean_title:
        score += 30
    
    # Check for official site indicators
    official_indicators = ['official site', 'official website', 'homepage', 'home page']
    if any(indicator in title_lower for indicator in official_indicators):
        score += 20
    
    # Negative signals - these are NOT what we want
    bad_patterns = [
        'wikipedia', 'wiki', 'linkedin', 'facebook', 'twitter', 'instagram', 'allabolag'
        'crunchbase', 'bloomberg', 'yahoo finance', 'google maps',
        'yelp', 'tripadvisor', 'directory', 'yellow pages',
        'search', 'find', 'locate', 'list of', 'companies like',
        'careers at', 'jobs at', 'reviews of', 'complaints about',
        'news about', 'articles about', 'information about'
    ]
    
    for pattern in bad_patterns:
        if pattern in title_lower:
            score -= 50
            break
    
    # Check for overly generic titles
    if len(clean_title) < 3 or len(title.split()) > 15:
        score -= 20
    
    return score


def clean_company_name(title: str) -> str:
    """
    Clean up company name from search result title.
    Remove common suffixes, separators, and noise.
    """
    # Split on common separators and take first part
    for sep in [' - ', ' ‚Äì ', ' ‚Äî ', ' | ', ' : ', ' :: ']:
        if sep in title:
            parts = title.split(sep)
            # Take the first non-empty part
            for part in parts:
                part = part.strip()
                if len(part) > 2 and not is_generic_suffix(part):
                    title = part
                    break
            break
    
    # Remove common trailing patterns
    patterns_to_remove = [
        r'\s*-\s*Official Site.*$',
        r'\s*\|\s*Official.*$',
        r'\s*-\s*Wikipedia.*$',
        r'\s*-\s*LinkedIn.*$',
        r'\s*-\s*Crunchbase.*$',
        r'\s*-\s*Home.*$',
        r'\s*-\s*About.*$',
        r'\s*\(.*?\)\s*$',  # Remove trailing parentheses
        r'\s*\.{2,}$',  # Remove trailing ellipsis
        r'\s*-\s*GOV\.UK$',
        r'\s*-\s*Find and update company information$',
        r'\s*-\s*Company Profile$',
    ]
    
    for pattern in patterns_to_remove:
        title = re.sub(pattern, '', title, flags=re.IGNORECASE)
    
    # Clean up extra whitespace
    title = ' '.join(title.split())
    
    return title.strip()


def is_generic_suffix(text: str) -> bool:
    """Check if text is a generic suffix we should ignore"""
    generic = [
        'official site', 'official website', 'home', 'homepage',
        'about us', 'about', 'wikipedia', 'linkedin', 'facebook',
        'overview', 'profile', 'crunchbase', 'company profile'
    ]
    return text.lower().strip() in generic


def format_domain_name(domain: str) -> str:
    """Format domain name as a fallback company name"""
    # Remove common TLD
    domain = re.sub(r'\.(com|org|net|io|co|uk|us|in)$', '', domain, flags=re.IGNORECASE)
    
    # Handle mixed names like 87sixty -> "87sixty" (keep original casing)
    if any(c.isdigit() for c in domain):
        # Split on digit boundaries
        parts = re.split(r'(\d+)', domain)
        return ''.join([p.title() if p and not p.isdigit() else p for p in parts if p])
    
    return domain.title()


def search_company_with_fallbacks(email: str) -> str:
    """
    Main function that tries multiple search engines with fallbacks
    """
    domain = email.split('@')[-1].strip()
    
    print(f"üöÄ Starting company search for: {email}")
    print(f"üìß Domain: {domain}")
    
    # Try Google first
    print("\n" + "="*50)
    print("üîç ATTEMPT 1: Google Search")
    print("="*50)
    result = search_company_google(email)
    if result:
        return result
    
    # Try Bing if Google fails
    print("\n" + "="*50)
    print("üîç ATTEMPT 2: Bing Search")
    print("="*50)
    result = search_company_bing(email)
    if result:
        return result
    
    # Try DuckDuckGo if Bing fails
    print("\n" + "="*50)
    print("üîç ATTEMPT 3: DuckDuckGo Search")
    print("="*50)
    result = search_company_duckduckgo(email)
    if result:
        return result
    
    # Final fallback to formatted domain
    print("\n" + "="*50)
    print("‚ö†Ô∏è ALL SEARCH ENGINES FAILED - USING DOMAIN FALLBACK")
    print("="*50)
    fallback = format_domain_name(domain.split('.')[0])
    print(f"‚ö†Ô∏è Using fallback: {fallback}")
    return fallback

